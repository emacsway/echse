/* An in-place binary trie implementation for C and C++ aka. the
ridiculously fast way of indexing stuff. (C) 2010-2012 Niall Douglas.


Boost Software License - Version 1.0 - August 17th, 2003

Permission is hereby granted, free of charge, to any person or organization
obtaining a copy of the software and accompanying documentation covered by
this license (the "Software") to use, reproduce, display, distribute,
execute, and transmit the Software, and to prepare derivative works of the
Software, and to permit third-parties to whom the Software is furnished to
do so, all subject to the following:

The copyright notices in the Software and this entire statement, including
the above license grant, this restriction and the following disclaimer,
must be included in all copies of the Software, in whole or in part, and
all derivative works of the Software, unless such copies or derivative
works are solely in the form of machine-executable object code generated by
a source language processor.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
DEALINGS IN THE SOFTWARE.
*/

#include <assert.h>
#include <stdint.h>
#include <stdlib.h>
#include <string.h> /* for memset */
#include <limits.h> /* For INT_MAX */

/*! \def NEDTRIEDEBUG
\brief Define to 1 if you wish a full trie validation to be performed every time you modify the trie.
Requires assert() to work, so disables itself if NDEBUG is defined.
*/
#ifndef NEDTRIEDEBUG
#ifdef DEBUG
#define NEDTRIEDEBUG 1
#else
#define NEDTRIEDEBUG 0
#endif
#endif
#ifdef NDEBUG
#undef NEDTRIEDEBUG
#define NEDTRIEDEBUG 0
#endif

/* Define bit scanning intrinsics */
#ifdef _MSC_VER
#include <intrin.h>
#endif

static inline unsigned nedtriebitscanr(size_t value)
{
  if(!value) return 0;
#if defined(__GNUC__)
  return sizeof(value)*CHAR_BIT - 1 - (unsigned) __builtin_clzl(value);
#else
  /* The following code is illegal C, but it almost certainly will work.
  If not use the legal implementation below */
	union {
		unsigned asInt[2];
		double asDouble;
	};
	int n;

	asDouble = (double)value + 0.5;
	n = (asInt[0 /*Use 1 if your CPU is big endian!*/] >> 20) - 1023;
#warning Make sure you change the line above me if your CPU is big endian!
	return (unsigned) n;
#endif
}

/*! \def NEDTRIE_INDEXBINS
\brief Defines the number of top level bit bins to use. The default based on size_t is usually fine.
*/
#define NEDTRIE_INDEXBINS (8*sizeof(void *))
/*! \def NEDTRIE_HEAD
\brief Substitutes the type used to store the head of the trie.
*/
#define NEDTRIE_HEAD2(name, type) \
typedef struct {                    \
  size_t count;                  \
  type *triebins[NEDTRIE_INDEXBINS]; /* each containing (1<<x)<=bitscanrev(x)<(1<<(x+1)) */ \
  int nobbledir;                 \
} name
#define NEDTRIE_HEAD(name, type) NEDTRIE_HEAD2(name, type)
/*! \def NEDTRIE_ENTRY
\brief Substitutes the type used to store the per-node trie information. Occupies 5*sizeof(size_t).
*/
#define NEDTRIE_ENTRY(type) \
struct {                   \
  type *trie_parent;           /* parent element */		\
  type *trie_child[2];         /* my children based on whether they are zero or one. */		\
  type *trie_prev, *trie_next; /* my siblings of identical key to me. */    \
}
#define NEDTRIE_INITIALIZER(root)
/*! \def NEDTRIE_INIT
\brief Initialises a nedtrie for usage.
*/
#define NEDTRIE_INIT(root) do { memset((root), 0, sizeof(*(root))); } while(0)
/*! \def NEDTRIE_EMPTY
\brief Returns whether a nedtrie is empty.
*/
#define NEDTRIE_EMPTY(head) (!(head)->count)
/*! \def NEDTRIE_COUNT
\brief Returns the number of items in a nedtrie.
*/
#define NEDTRIE_COUNT(head) ((head)->count)

#define NEDTRIE_NOBBLEZEROS(name)   name##_nobblezeros
#define NEDTRIE_NOBBLEONES(name)    name##_nobbleones
#define NEDTRIE_NOBBLEEQUALLY(name) name##_nobbleequally
#define NEDTRIE_GENERATE_NOBBLES(proto, name, type, field, keyfunct) \
  static inline __attribute__((unused)) int name##_nobblezeros(name *head) { (void) head; return 0; } \
  static inline __attribute__((unused)) int name##_nobbleones(name *head) { (void) head; return 1; } \
  static inline __attribute__((unused)) int name##_nobbleequally(name *head) { return (head->nobbledir=!head->nobbledir); }

/* GCC recently has started puking if you use operators -> and & in template parameters :( */
#ifdef __GNUC__
#define NEDTRIEFIELDOFFSET2(type, field) __builtin_offsetof(type, field)
#else
#define NEDTRIEFIELDOFFSET2(type, field) ((size_t) &(((type *)0)->field))
#endif
#define NEDTRIEFIELDOFFSET(type, field) NEDTRIEFIELDOFFSET2(type, field)

#define NEDTRIE_GENERATE_INSERT(proto, name, type, field, keyfunct) \
  proto inline __attribute__((unused)) void name##_NEDTRIE_INSERT(name *restrict head, type *restrict r) \
  { \
    type *restrict node, *restrict childnode; \
    size_t rkey=keyfunct(r), keybit, nodekey; \
    unsigned bitidx; \
    int keybitset; \
\
    memset(&r->field, 0, sizeof(r->field)); \
    bitidx=nedtriebitscanr(rkey); \
    assert(bitidx<NEDTRIE_INDEXBINS); \
    if(!(node=head->triebins[bitidx])) \
    { /* Bottom two bits set indicates a node hanging off of head */ \
      r->field.trie_parent=(type *)(size_t)(3|(bitidx<<2)); \
      head->triebins[bitidx]=r; \
      goto end; \
    } \
    /* Avoid variable bit shifts where possible, their performance can suck */ \
    keybit=(size_t) 1<<bitidx; \
    for(;;node=childnode) \
    { \
      nodekey=keyfunct(node); \
      if(nodekey==rkey) \
      { /* Insert into ring list */ \
        r->field.trie_parent=0; \
        r->field.trie_prev=node; \
        r->field.trie_next=node->field.trie_next; \
        node->field.trie_next=r; \
        if(r->field.trie_next) r->field.trie_next->field.trie_prev=r; \
        break; \
      } \
      keybit>>=1; \
      keybitset=!!(rkey&keybit); \
      childnode=node->field.trie_child[keybitset]; \
      if(!childnode) \
      { /* Insert here */ \
        r->field.trie_parent=node; \
        node->field.trie_child[keybitset]=r; \
        break; \
      } \
    } \
end: \
    head->count++; \
  }

#define NEDTRIE_GENERATE_REMOVE(proto, name, type, field, keyfunct, nobblefunct) \
  proto inline __attribute__((unused)) void name##_NEDTRIE_REMOVE(name *restrict head, type *restrict r)		\
  { \
    type *restrict node, **myaddrinparent=0; \
    unsigned bitidx; \
\
    /* Am I a leaf off the tree? */ \
    if(r->field.trie_prev) \
    { /* Remove from linked list */ \
      assert(!r->field.trie_parent); \
      node=r->field.trie_prev; \
      node->field.trie_next=r->field.trie_next; \
      if(r->field.trie_next) \
      { \
        r->field.trie_next->field.trie_prev=node; \
      } \
      goto functexit; \
    } \
    /* I must therefore be part of the tree */ \
    assert(r->field.trie_parent); \
    assert(!r->field.trie_prev); \
    /* Am I at the top of the tree? */ \
    if(((size_t) r->field.trie_parent & 3)==3) \
    { /* Extract my bitidx */ \
      bitidx=(unsigned)(((size_t) r->field.trie_parent)>>2); \
      assert(head->triebins[bitidx]==r); \
      /* Set the node addr to be modified */ \
      myaddrinparent=&head->triebins[bitidx]; \
    } \
    else \
    { /* Otherwise I am one of my parent's children */ \
      node=r->field.trie_parent; \
      myaddrinparent=(node->field.trie_child[0]==r) ? &node->field.trie_child[0] : &node->field.trie_child[1]; \
    } \
    assert(*myaddrinparent==r); \
    node=0; \
    /* Can I replace me with a sibling? */ \
    if(r->field.trie_next) \
    { \
      node=r->field.trie_next; \
      assert(node->field.trie_prev==r); \
      node->field.trie_prev=0; \
      goto end; \
    } \
    /* Can I simply remove myself from my parent? */ \
    if(!r->field.trie_child[0] && !r->field.trie_child[1]) \
      goto end; \
    /* I need someone to replace me in the trie, so simply find any \
       grandchild of mine (who has the right bits to be here) which has no children. \
    */ \
    { \
      type *restrict *restrict childaddrinparent=myaddrinparent, *restrict *restrict newchildaddrinparent; \
      int nobbledir=nobblefunct(head); \
      while(*(newchildaddrinparent=&(*childaddrinparent)->field.trie_child[nobbledir]) \
         || *(newchildaddrinparent=&(*childaddrinparent)->field.trie_child[!nobbledir])) \
        childaddrinparent=newchildaddrinparent; \
      node=*childaddrinparent; \
      *childaddrinparent=0; \
    } \
  end: \
    if(node) \
    { \
      assert(!node->field.trie_child[0] && !node->field.trie_child[1]); \
      node->field.trie_parent=r->field.trie_parent; \
      node->field.trie_child[0]=r->field.trie_child[0]; \
      node->field.trie_child[1]=r->field.trie_child[1]; \
      if(node->field.trie_child[0]) \
      { \
        node->field.trie_child[0]->field.trie_parent=node; \
      } \
      if(node->field.trie_child[1]) \
      { \
        node->field.trie_child[1]->field.trie_parent=node; \
      } \
    } \
    *myaddrinparent=node; \
  functexit: \
    head->count--; \
  }

#define NEDTRIE_GENERATE_FIND(proto, name, type, field, keyfunct) \
  proto inline __attribute__((unused)) type * name##_NEDTRIE_FIND(name *restrict head, type *restrict r)		\
  { \
    type *restrict node, *restrict childnode; \
    size_t rkey=keyfunct(r), keybit, nodekey; \
    unsigned bitidx; \
    int keybitset; \
\
    if(!head->count) return 0; \
    bitidx=nedtriebitscanr(rkey); \
    assert(bitidx<NEDTRIE_INDEXBINS); \
    if(!(node=head->triebins[bitidx])) \
      return 0; \
    /* Avoid variable bit shifts where possible, their performance can suck */ \
    keybit=(size_t) 1<<bitidx; \
    for(;;node=childnode) \
    { \
      nodekey=keyfunct(node); \
      if(nodekey==rkey) \
        goto end; \
      keybit>>=1; \
      keybitset=!!(rkey&keybit); \
      childnode=node->field.trie_child[keybitset]; \
      if(!childnode) \
        return 0; \
    } \
    /* not reached */ \
    ; \
  end: \
    return node->field.trie_next ? node->field.trie_next : node; \
  }

#define NEDTRIE_GENERATE_EXACTFIND(proto, name, type, field, keyfunct) \
  proto inline __attribute__((unused)) int name##_NEDTRIE_EXACTFIND(name *restrict head, type *restrict r)		\
  { \
    type *restrict node; \
\
    if(!head->count) return 0; \
    if(!(node=name##_NEDTRIE_FIND(head, r))) return 0; \
    if(node->field.trie_prev) node=node->field.trie_prev; \
    do \
    { \
      if(node==r) return 1; \
      node=node->field.trie_next; \
    } while(node); \
    return 0; \
  }

#define NEDTRIE_GENERATE_CFIND(proto, name, type, field, keyfunct) \
  proto inline __attribute__((unused)) type * name##_NEDTRIE_CFIND(name *restrict head, type *restrict r, int rounds)		\
  { \
    type *restrict node=0, *restrict childnode, *restrict ret=0; \
    size_t rkey=keyfunct(r), keybit, nodekey; \
    unsigned binbitidx; \
    int keybitset; \
 \
    if(!head->count) return 0; \
    binbitidx=nedtriebitscanr(rkey); \
    assert(binbitidx<NEDTRIE_INDEXBINS); \
    do \
    { \
      size_t retkey=(size_t)-1; \
      unsigned bitidx; \
      /* Keeping raising the bin until we find a larger key */ \
      while(binbitidx<NEDTRIE_INDEXBINS && !(node=head->triebins[binbitidx])) \
        binbitidx++; \
      if(binbitidx>=NEDTRIE_INDEXBINS) \
        return 0; \
      bitidx=binbitidx; \
      /* Avoid variable bit shifts where possible, their performance can suck */ \
      keybit=(size_t) 1<<bitidx; \
      nodekey=keyfunct(node); \
      /* If nodekey is a closer fit to search key, mark as best result so far */ \
      if(nodekey>=rkey && nodekey-rkey<retkey) \
      { \
        ret=node; \
        retkey=nodekey-rkey; \
      } \
      if(rounds--<=0 && ret) return ret; \
      for(;;node=childnode) \
      { \
        /* If a child is a closer fit to search key, mark as best result so far */ \
        if(node->field.trie_child[0]) \
        { \
          nodekey=keyfunct(node->field.trie_child[0]); \
          if(nodekey>=rkey && nodekey-rkey<retkey) \
          { \
            ret=node->field.trie_child[0]; \
            retkey=nodekey-rkey; \
          } \
        } \
        if(node->field.trie_child[1]) \
        { \
          nodekey=keyfunct(node->field.trie_child[1]); \
          if(nodekey>=rkey && nodekey-rkey<retkey) \
          { \
            ret=node->field.trie_child[1]; \
            retkey=nodekey-rkey; \
          } \
        } \
        if(rounds--<=0 && ret) return ret; \
        /* Which child branch should we check? */ \
        keybit>>=1; \
        keybitset=!!(rkey&keybit); \
        childnode=node->field.trie_child[keybitset]; \
        /* If no child and we were checking lowest, check highest */ \
        if(!childnode && !keybitset) \
          childnode=node->field.trie_child[1]; \
        if(!childnode) break; \
      } \
      if(!ret) \
      { /* If we didn't find any node bigger than rkey, bump up a bin \
           and look for the smallest possible key in that */ \
        binbitidx++; \
        /* From now on, always match lowest */ \
        retkey+=rkey; \
        rkey=0; \
        continue; \
      } \
    } while(!ret); \
    return ret->field.trie_next ? ret->field.trie_next : ret; \
  }

#define NEDTRIE_GENERATE_MINMAX(proto, name, type, field, keyfunct) \
  proto inline __attribute__((unused)) type * name##_NEDTRIE_MINMAX(name *restrict head, const unsigned dir)		\
  { \
    type *restrict node=0, *restrict child; \
    unsigned bitidx; \
    if(!head->count) return 0; \
    if(!dir) \
    { /* He wants min */ \
      for(bitidx=0; bitidx<NEDTRIE_INDEXBINS && !(node=head->triebins[bitidx]); bitidx++); \
      assert(node); \
      return node; \
    } \
    /* He wants max */ \
    for(bitidx=NEDTRIE_INDEXBINS-1; bitidx<NEDTRIE_INDEXBINS && !(node=head->triebins[bitidx]); bitidx--); \
    assert(node); \
    while((child=node->field.trie_child[1] ? node->field.trie_child[1] : node->field.trie_child[0])) \
    { \
      node=child; \
    } \
    /* Now go to end leaf */ \
    while(node->field.trie_next) \
    { \
      node=node->field.trie_next; \
    } \
    return node; \
  }

#define NEDTRIE_GENERATE_PREV(proto, name, type, field, keyfunct) \
  proto inline __attribute__((unused)) type * name##_NEDTRIE_BRANCHPREV(type *restrict *restrict r)		\
  { \
    type *restrict node=0, *restrict child; \
\
    /* Am I a leaf off the tree? */ \
    if((*r)->field.trie_prev) \
    { \
      assert(!(*r)->field.trie_parent); \
      return (*r)->field.trie_prev; \
    } \
    /* Trace up my parents to prev branch */ \
    while(((size_t) (*r)->field.trie_parent & 3)!=3) \
    { \
      node=(*r)->field.trie_parent; \
      /* If I was on child[1] and there is a child[0], go to bottom of child[0] */ \
      if(node->field.trie_child[1]==(*r) && node->field.trie_child[0]) \
      { \
        node=node->field.trie_child[0]; \
        /* Follow child[1] preferentially downwards */ \
        while((child=node->field.trie_child[1] ? node->field.trie_child[1] : node->field.trie_child[0])) \
        { \
          node=child; \
        } \
      } \
      /* If I was already on child[0] or there are no more children, return this node */ \
      /* Now go to end leaf */ \
      while(node->field.trie_next) \
      { \
        node=node->field.trie_next; \
      } \
      return node; \
    } \
    /* I have reached the top of my trie, no more on this branch */ \
    return 0; \
  } \
  proto inline __attribute__((unused)) type * name##_NEDTRIE_PREV(name *restrict head, type *restrict r)		\
  { \
    type *restrict node=0, *restrict child; \
    unsigned bitidx; \
\
    if((node=name##_NEDTRIE_BRANCHPREV(&r))) return node; \
    /* I have reached the top of my trie, so on to prev bin */ \
    bitidx=(unsigned)(((size_t) r->field.trie_parent)>>2); \
    assert(head->triebins[bitidx]==r); \
    for(bitidx--; bitidx<NEDTRIE_INDEXBINS && !(node=head->triebins[bitidx]); bitidx--); \
    if(bitidx>=NEDTRIE_INDEXBINS) return 0; \
    /* Follow child[1] preferentially downwards */ \
    while((child=node->field.trie_child[1] ? node->field.trie_child[1] : node->field.trie_child[0])) \
    { \
      node=child; \
    } \
    /* Now go to end leaf */ \
    while(node->field.trie_next) \
    { \
      node=node->field.trie_next; \
    } \
    return node; \
  }

#define NEDTRIE_GENERATE_NEXT(proto, name, type, field, keyfunct) \
  proto inline __attribute__((unused)) type * name##_NEDTRIE_BRANCHNEXT(type *restrict *restrict r)		\
  { \
    type *restrict node; \
\
    /* Am I a leaf off the tree? */ \
    if((*r)->field.trie_next) \
      return (*r)->field.trie_next; \
    /* If I am the end leaf off a tree, put me back at my tree node */ \
    while(!(*r)->field.trie_parent) \
    { \
      (*r)=(*r)->field.trie_prev; \
    } \
    /* Follow my children, preferring child[0] */ \
    if((node=(*r)->field.trie_child[0] ? (*r)->field.trie_child[0] : (*r)->field.trie_child[1])) \
    { \
      assert(node->field.trie_parent==(*r)); \
      return node; \
    } \
    /* Trace up my parents to next branch */ \
    while(((size_t) (*r)->field.trie_parent & 3)!=3) \
    { \
      node=(*r)->field.trie_parent; \
      if(node->field.trie_child[0]==(*r) && node->field.trie_child[1]) \
      { \
        return node->field.trie_child[1]; \
      } \
      (*r)=node; \
    } \
    return 0; \
  } \
  proto inline __attribute__((unused)) type * name##_NEDTRIE_NEXT(name *restrict head, type *restrict r)		\
  { \
    type *restrict node; \
    unsigned bitidx; \
\
    if((node=name##_NEDTRIE_BRANCHNEXT(&r))) return node; \
    /* I have reached the top of my trie, so on to next bin */ \
    bitidx=(unsigned)(((size_t) r->field.trie_parent)>>2); \
    assert(head->triebins[bitidx]==r); \
    for(bitidx++; bitidx<NEDTRIE_INDEXBINS && !(node=head->triebins[bitidx]); bitidx++); \
    if(bitidx>=NEDTRIE_INDEXBINS) return 0; \
    return node; \
  }

#define NEDTRIE_GENERATE_NFIND(proto, name, type, field, keyfunct) \
  proto inline __attribute__((unused)) type * name##_NEDTRIE_NFIND(name *restrict head, type *restrict r)		\
  { \
    type *restrict node=0, *restrict ret=name##_NEDTRIE_CFIND(head, r, INT_MAX), *restrict stop; \
    size_t rkey=keyfunct(r), retkey, nodekey; \
    \
    if(!ret) return 0; \
    if(!(retkey=keyfunct(ret)-rkey)) return ret; \
    /* Cfind basically does a find but if it doesn't find an exact match it early outs    \
    with the closest result it found during the find. As nodes with children have a key   \
    which is only guaranteed to be correct under its parent's constraints and has nothing \
    to do with its children, there may be a closer key in any of the children of the node \
    returned. Hence we iterate the local subbranch, looking for closer fits. */           \
    stop=r->field.trie_parent; \
    for(node=ret, node=name##_NEDTRIE_BRANCHNEXT(&node); node && node!=stop; node=name##_NEDTRIE_BRANCHNEXT(&node)) \
    { \
      nodekey=keyfunct(node); \
      /* If nodekey is a closer fit to search key, mark as best result so far */ \
      if(nodekey>=rkey && nodekey-rkey<retkey) \
      { \
        ret=node; \
        retkey=nodekey-rkey; \
      } \
    } \
    return ret; \
  }

/*! \def NEDTRIE_GENERATE
\brief Substitutes a set of nedtrie implementation function definitions specialised according to type.
*/
#define NEDTRIE_GENERATE(proto, name, type, field, keyfunct, nobblefunct) \
  NEDTRIE_GENERATE_NOBBLES  (proto, name, type, field, keyfunct) \
  NEDTRIE_GENERATE_INSERT   (proto, name, type, field, keyfunct) \
  NEDTRIE_GENERATE_REMOVE   (proto, name, type, field, keyfunct, nobblefunct) \
  NEDTRIE_GENERATE_FIND     (proto, name, type, field, keyfunct) \
  NEDTRIE_GENERATE_EXACTFIND(proto, name, type, field, keyfunct) \
  NEDTRIE_GENERATE_CFIND    (proto, name, type, field, keyfunct) \
  NEDTRIE_GENERATE_MINMAX   (proto, name, type, field, keyfunct) \
  NEDTRIE_GENERATE_PREV     (proto, name, type, field, keyfunct) \
  NEDTRIE_GENERATE_NEXT     (proto, name, type, field, keyfunct) \
  NEDTRIE_GENERATE_NFIND    (proto, name, type, field, keyfunct) \
  proto inline __attribute__((unused)) type * name##_NEDTRIE_PREVLEAF(type *r) { return (r)->field.trie_prev; } \
  proto inline __attribute__((unused)) type * name##_NEDTRIE_NEXTLEAF(type *r) { return (r)->field.trie_next; } \
  typedef void nedtrie_generated_t

/*! \def NEDTRIE_INSERT
\brief Inserts item y into nedtrie x.
*/
#define NEDTRIE_INSERT(name, x, y)       name##_NEDTRIE_INSERT(x, y)
/*! \def NEDTRIE_REMOVE
\brief Removes item y from nedtrie x.
*/
#define NEDTRIE_REMOVE(name, x, y)       name##_NEDTRIE_REMOVE(x, y)
/*! \def NEDTRIE_FIND
\brief Finds the item with the same key as y in nedtrie x.
*/
#define NEDTRIE_FIND(name, x, y)         name##_NEDTRIE_FIND(x, y)
/*! \def NEDTRIE_EXACTFIND
\brief Returns true if there is an item with the same key and address as y in nedtrie x.
*/
#define NEDTRIE_EXACTFIND(name, x, y)    name##_NEDTRIE_EXACTFIND(x, y)
/*! \def NEDTRIE_CFIND
\brief Performs \em rounds number of attempts to find an item with an equal key to y in nedtrie x, and
if none equal then the closest item with a larger key. Always returns a larger key if there is a larger
key in the trie, if there isn't it returns zero. Think of rounds as how closely you want the find to fit
the requested key, so \c INT_MAX means "as close as possible". Note that Cfind does NOT guarantee that
the item returned is the next largest keyed item, use Nfind for that.
*/
#define NEDTRIE_CFIND(name, x, y, rounds) name##_NEDTRIE_CFIND(x, y, rounds)
/*! \def NEDTRIE_NFIND
\brief Finds an item with an equal key to y in nedtrie x, and if none equal then the item with the next
largest key. If the key is not equal, the returned item is guaranteed to be the next largest keyed item.
*/
#define NEDTRIE_NFIND(name, x, y)        name##_NEDTRIE_NFIND(x, y)
/*! \def NEDTRIE_PREV
\brief Returns the item preceding y in nedtrie x.
*/
#define NEDTRIE_PREV(name, x, y)         name##_NEDTRIE_PREV(x, y)
/*! \def NEDTRIE_NEXT
\brief Returns the item following y in nedtrie x.
*/
#define NEDTRIE_NEXT(name, x, y)         name##_NEDTRIE_NEXT(x, y)
/*! \def NEDTRIE_PREVLEAF
\brief Returns the item with an identical key preceding y in nedtrie x.
*/
#define NEDTRIE_PREVLEAF(name, x)        name##_NEDTRIE_PREVLEAF(x)
/*! \def NEDTRIE_NEXTLEAF
\brief Returns the item with an identical key following y in nedtrie x.
*/
#define NEDTRIE_NEXTLEAF(name, x)        name##_NEDTRIE_NEXTLEAF(x)
/*! \def NEDTRIE_MIN
\brief Returns the lowest item in nedtrie x. This item will approximately have the smallest key.
*/
#define NEDTRIE_MIN(name, x)             name##_NEDTRIE_MINMAX(x, 0)
/*! \def NEDTRIE_MAX
\brief Returns the highest item in nedtrie x. This item will approximately have the biggest key.
*/
#define NEDTRIE_MAX(name, x)             name##_NEDTRIE_MINMAX(x, 1)

/*! \def NEDTRIE_FOREACH
\brief Substitutes a for loop which forward iterates into x all items in nedtrie head. Order of
items is mostly in key order (enough that a bubble sort is efficient).
*/
#define NEDTRIE_FOREACH(type, x, name, head)	      \
	for (type *x = NEDTRIE_MIN(name, head);           \
	     (x) != NULL;                             \
	     (x) = NEDTRIE_NEXT(name, head, x))

/*! \def NEDTRIE_FOREACH_SAFE
\brief Substitutes a for loop which forward iterates into x all items in
nedtrie head and is safe against removal of x. Order of items is mostly
in key order (enough that a bubble sort is efficient).
*/
#define NEDTRIE_FOREACH_SAFE(type, x, name, head, y)   \
	for (type *x = NEDTRIE_MIN(name, head);           \
	     (x) != NULL && ((y) = NEDTRIE_NEXT(name, head, x), 1); \
	     (x) = (y))

/*! \def NEDTRIE_FOREACH_REVERSE
\brief Substitutes a for loop which reverse iterates into x all items in nedtrie head. Order of
items is mostly inverse to key order (enough that a bubble sort is efficient).
*/
#define NEDTRIE_FOREACH_REVERSE(x, name, head)  \
	for ((x) = NEDTRIE_MAX(name, head);           \
	     (x) != NULL;                             \
	     (x) = NEDTRIE_PREV(name, head, x))

/*! \def NEDTRIE_FOREACH_REVERSE_SAFE
\brief Substitutes a for loop which reverse iterates into x all items in nedtrie head and is
safe against removal of x. Order of items is mostly inverse to key order (enough that a bubble
sort is efficient).
*/
#define NEDTRIE_FOREACH_REVERSE_SAFE(x, name, head, y)  \
	for ((x) = NEDTRIE_MAX(name, head);           \
	     (x) != NULL && ((y) = NEDTRIE_PREV(name, head, x), 1); \
	     (x) = (y))

/*! \def NEDTRIE_HASNODEHEADER
\brief Returns true if this item's node header is active. Useful as a quick check for whether a node is in some trie.
*/
#define NEDTRIE_HASNODEHEADER(treevar, node, link)  ((node)->link.trie_parent || (node)->link.trie_prev)
